{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C_XUy10uGlZu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hvOjIj_GlZw"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MKvQFw_GlZz"
      },
      "source": [
        "Materials by Francesco Periti and Elisabetta Rocchetti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb1CEAsJGlZ0"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNQa4fCuGlZ3"
      },
      "source": [
        "Transformers recap:\n",
        "<center><img src=\"https://pytorch.org/tutorials/_images/transformer_architecture.jpg\" width=\"30%\"/></center>\n",
        "Both the decoder and the encoder have language understanding. Idea: use only either the decoder or the encoder!\n",
        "\n",
        "Example of Transformer models in real world:\n",
        "\n",
        "- Generative Pre-Training or GPT (Radford et al., “Improving Language Understanding by Generative Pre-Training.”)\n",
        "- Bidirectional Encoder Representations from Transformers or BERT (Devlin et al., “BERT.”)\n",
        "\n",
        "GPT looks like this:\n",
        "<center><img src=\"https://github.com/Abudo-S/NLP_COURSE/blob/main/BERT/img/gpt.png?raw=1\" width=\"30%\"/></center>\n",
        "\n",
        "Main properties of GPT:\n",
        "\n",
        "- transfer learning paradigm\n",
        "- based on Transformers decoder\n",
        "\n",
        "BERT looks like this:\n",
        "<center><img src=\"https://github.com/Abudo-S/NLP_COURSE/blob/main/BERT/img/bert.png?raw=1\" width=\"30%\"/></center>\n",
        "\n",
        "Main properties of BERT:\n",
        "\n",
        "- transfer learning paradigm\n",
        "- based on Transformers encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thsSA1tOGlZ5"
      },
      "source": [
        "## Transfer learning\n",
        "\n",
        "But... what is transfer learning? Training procedure in 2 steps:\n",
        "\n",
        "1. Pre-training: understand language $\\rightarrow$ high computational cost\n",
        "2. Fine tuning: understand how to solve task, given that I have language knowledge $\\rightarrow$ low computational cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvJWlzz2GlZ7"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFtqUOLrGlZ8"
      },
      "source": [
        "### Motivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSIXVe7fGlZ9"
      },
      "source": [
        "Why BERT? Unlike GPT, it is bidirectional: this means that it can learn from both left and right context! c:\n",
        "\n",
        "... but we loose the benefits of masked multi-head attention :c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9hMcIErGlZ_"
      },
      "source": [
        "### Architecture\n",
        "\n",
        "<center><img src=\"https://github.com/Abudo-S/NLP_COURSE/blob/main/BERT/img/bert.svg?raw=1\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdcbmH5yGlaA"
      },
      "source": [
        "### Input/Output Representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfCr1gwAGlaB"
      },
      "source": [
        "Expected input: either a single sentence or a pair of sentences.\n",
        "\n",
        "Tokenization: WordPiece tokenizer [Wu et al., “Google’s Neural Machine Translation System.”].\n",
        "\n",
        "The sequence must start with $\\text{[CLS]}$, and each sentence must end with $\\text{[SEP]}$.\n",
        "$$\\text{Raccoons love eating. They are playful.} \\rightarrow \\text{[CLS] Raccoons love eating. [SEP] They are playful. [SEP]}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBUiTtiGGlaC"
      },
      "source": [
        "### Details on WordPiece tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD4lwG5vGlaD"
      },
      "source": [
        "This implementation of WordPiece tokenizer is similar to Byte-Pair Encoding [Sennrich, Haddow, and Birch, “Neural Machine Translation of Rare Words with Subword Units.”] and is described in more detail in [Schuster and Nakajima, “Japanese and Korean Voice Search.”].  \n",
        "Subword Units: Words are broken down into smaller pieces. For instance, \"tokenization\" might be split into \"token\", \"##ization\". The \"##\" prefix indicates that the subword is a continuation of a previous word.\n",
        "\n",
        "Handling OOV Words: This is a major advantage. If the model encounters a word it has never seen before, like \"unbelievable,\" it can break it down into known subwords like \"un\", \"##believ\", and \"##able\". The model then understands the new word based on its known parts.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Extract all the words from the dataset along with their count\n",
        "2. Split all the words into character sequences\n",
        "3. Define a vocabulary size\n",
        "4. Add all the unique characters present in the character sequences to the vocabulary\n",
        "5. Identify symbol pair having the highest score. Merge it, and add it to the vocabulary\n",
        "6. Repeat Step 5 until you reach the vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cy4sNmH2GlaD",
        "outputId": "d5394f8f-f126-44b3-ab77-577c099595f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.32.4)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n",
            "Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.12/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch6detail10class_baseC2ERKSsS3_SsRKSt9type_infoS6_",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2526875281.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torchtext'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.12/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch6detail10class_baseC2ERKSsS3_SsRKSt9type_infoS6_"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "import torchtext\n",
        "from torch.utils.data import DataLoader\n",
        "import datasets\n",
        "\n",
        "dataset = torchtext.datasets.AG_NEWS(split = 'train')\n",
        "batch_size = 30\n",
        "data_loader = iter(DataLoader(dataset, batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "roL8JGioGlaE",
        "outputId": "45ecff84-26c4-4a98-f873-6d3327afbd4a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1431822854.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"
          ]
        }
      ],
      "source": [
        "for s in data_loader:\n",
        "    print(s)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xzI5B61GlaH"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "class WordPieceTokenizer:\n",
        "    def __init__(self, vocabulary_size):\n",
        "        self.word_counter = Counter()\n",
        "        #3\n",
        "        self.vocab_size = vocabulary_size\n",
        "        #4 and 5\n",
        "        self.vocab = Counter()\n",
        "\n",
        "    #1\n",
        "    def extract_words(self, batch):\n",
        "        res_batch = []\n",
        "        for sentence in batch:\n",
        "            tokenized = nltk.word_tokenize(sentence.lower().strip())\n",
        "            self.word_counter.update(tokenized)\n",
        "            res_batch.append(tokenized)\n",
        "        return res_batch\n",
        "\n",
        "    #2\n",
        "    def split_char(self, batch):\n",
        "        res_batch = []\n",
        "        for sentence in batch:\n",
        "            res_batch.append([[c for c in word] for word in sentence])\n",
        "        return res_batch\n",
        "\n",
        "    #4\n",
        "    def add_unique_chars(self, batch):\n",
        "        batch_split = self.split_char(batch)\n",
        "        for sentence in batch_split:\n",
        "            for word in sentence:\n",
        "                self.vocab.update(word)\n",
        "\n",
        "    #5\n",
        "    def count_likelihood(self):\n",
        "        pair_counter = Counter()\n",
        "        for word, word_count in self.word_counter.items():\n",
        "            word = self.word_tokenize(word)\n",
        "            if len(word) < 2: continue\n",
        "            for i in range(len(word)-1):\n",
        "                pair_counter.update([(word[i], word[i+1])] * word_count)\n",
        "        likelihoods = {k: v/(self.vocab[k[0]]*self.vocab[k[1]]) for k, v in pair_counter.items()}\n",
        "        likelihoods = sorted(likelihoods.items(), key=lambda x: x[1])\n",
        "        return likelihoods, pair_counter\n",
        "\n",
        "    def add_frequent(self, logging = False):\n",
        "        while len(self.vocab) < self.vocab_size:\n",
        "            likelihoods, counter = self.count_likelihood()\n",
        "            found_next = False\n",
        "            while not found_next:\n",
        "                if not likelihoods: return len(self.vocab) < self.vocab_size\n",
        "                new_frequent_split = likelihoods.pop()\n",
        "                if not f'{new_frequent_split[0][0]}{new_frequent_split[0][1]}' in self.vocab: found_next = True\n",
        "            self.vocab.update({f'{new_frequent_split[0][0]}{new_frequent_split[0][1]}':counter[new_frequent_split[0]]})\n",
        "            if logging:\n",
        "                print(f'The pair \"{new_frequent_split[0][0]}{new_frequent_split[0][1]}\" having score {new_frequent_split[1]} has been added')\n",
        "                print(f'Updated vocabulary: {self.vocab}')\n",
        "        return len(self.vocab) == self.vocab_size\n",
        "\n",
        "    def word_tokenize(self, word):\n",
        "        if len(word)==1:\n",
        "            return [word]\n",
        "        splits = []\n",
        "        i = 0\n",
        "        word_temp = word\n",
        "        while ''.join(splits) !=  word:\n",
        "            if i < len(word_temp):\n",
        "                split = word_temp[0:len(word_temp)-i]\n",
        "                if split in self.vocab:\n",
        "                    splits.append(split)\n",
        "                    word_temp = word_temp[len(split):]\n",
        "                    i=0\n",
        "                else:\n",
        "                    i = i+1\n",
        "            else:\n",
        "                splits = splits + [word_temp]\n",
        "        return splits\n",
        "\n",
        "    def tokenize(self, sentence):\n",
        "        sentence_tokenized = []\n",
        "        for word in nltk.word_tokenize(sentence.lower().strip()):\n",
        "            sentence_tokenized.append(self.word_tokenize(word))\n",
        "        return sentence_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srq-yVn0GlaL",
        "outputId": "3dfeaa8e-489e-4c2f-9615-c0772aeba6d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['this', 'is', 'home'], ['house'], ['horse'], ['universe'], ['university']]\n",
            "Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'm': 1, 'y': 1})\n",
            "The pair \"ty\" having score 0.5 has been added\n",
            "Updated vocabulary: Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'm': 1, 'y': 1, 'ty': 1})\n",
            "The pair \"un\" having score 0.3333333333333333 has been added\n",
            "Updated vocabulary: Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'un': 2, 'm': 1, 'y': 1, 'ty': 1})\n",
            "The pair \"om\" having score 0.3333333333333333 has been added\n",
            "Updated vocabulary: Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'un': 2, 'm': 1, 'y': 1, 'ty': 1, 'om': 1})\n",
            "The pair \"hom\" having score 0.25 has been added\n",
            "Updated vocabulary: Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'un': 2, 'm': 1, 'y': 1, 'ty': 1, 'om': 1, 'hom': 1})\n",
            "The pair \"ity\" having score 0.2 has been added\n",
            "Updated vocabulary: Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'un': 2, 'm': 1, 'y': 1, 'ty': 1, 'om': 1, 'hom': 1, 'ity': 1})\n",
            "The pair \"iv\" having score 0.2 has been added\n",
            "Updated vocabulary: Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'un': 2, 'iv': 2, 'm': 1, 'y': 1, 'ty': 1, 'om': 1, 'hom': 1, 'ity': 1})\n",
            "The pair \"univ\" having score 0.5 has been added\n",
            "Updated vocabulary: Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'un': 2, 'iv': 2, 'univ': 2, 'm': 1, 'y': 1, 'ty': 1, 'om': 1, 'hom': 1, 'ity': 1})\n",
            "The pair \"sity\" having score 0.16666666666666666 has been added\n",
            "Updated vocabulary: Counter({'s': 6, 'e': 6, 'i': 5, 'h': 4, 'o': 3, 'u': 3, 'r': 3, 't': 2, 'n': 2, 'v': 2, 'un': 2, 'iv': 2, 'univ': 2, 'm': 1, 'y': 1, 'ty': 1, 'om': 1, 'hom': 1, 'ity': 1, 'sity': 1})\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "wptokenizer = WordPieceTokenizer(vocabulary_size=20)\n",
        "b = ['this is home', 'house', 'horse', 'universe', 'university']\n",
        "d = wptokenizer.extract_words(b)\n",
        "print(d)\n",
        "wptokenizer.add_unique_chars(d)\n",
        "print(wptokenizer.vocab)\n",
        "wptokenizer.add_frequent(logging = True)\n",
        "print(len(wptokenizer.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdFYjRKUGlaM",
        "outputId": "60a1d623-0fa5-49d9-d748-c17634da67db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['univ', 'e', 'r', 's', 'e']"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wptokenizer.word_tokenize('universe')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6T9iLCsGlaN",
        "outputId": "24e38d41-6a55-4dbb-f8cb-3f9ad06d72e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wptokenizer = WordPieceTokenizer(vocabulary_size=10000)\n",
        "_, b = next(data_loader)\n",
        "d = wptokenizer.extract_words(b)\n",
        "wptokenizer.add_unique_chars(d)\n",
        "wptokenizer.add_frequent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgLdu-bTGlaO",
        "outputId": "b9eab3e7-fc08-46ab-c468-2abb2666af62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example sentence: Downhome Pinoy Blues, Intersecting Life Paths, and Heartbreak Songs The Blues is alive and well in the Philippines, as evidenced by this appreciation of the Pinoy Blues band 'Lampano Alley', penned by columnist Clarence Henderson as a counterpoint to his usual economics, business, and culture fare.\n",
            "Tokenized:[['down', 'ho', 'm', 'e'], ['pin', 'o', 'y'], ['b', 'l', 'u', 'es'], [','], ['inter', 's', 'e', 'c', 't', 'ing'], ['l', 'if', 'e'], ['p', 'at', 'h', 's'], [','], ['and'], ['heart', 'break'], ['s', 'on', 'g', 's'], ['the'], ['b', 'l', 'u', 'es'], ['is'], ['al', 'ive'], ['and'], ['well'], ['in'], ['the'], ['philippines'], [','], ['as'], ['e', 'vi', 'de', 'n', 'ced'], ['by'], ['this'], ['a', 'p', 'pre', 'c', 'i', 'at', 'ion'], ['of'], ['the'], ['pin', 'o', 'y'], ['b', 'l', 'u', 'es'], ['band'], [\"'\", 'l', 'a', 'mp', 'an', 'o'], ['all', 'e', 'y'], [\"'\"], [','], ['p', 'e', 'n', 'ned'], ['by'], ['columnist'], ['c', 'l', 'are', 'n', 'c', 'e'], ['he', 'nd', 'ers', 'on'], ['as'], ['a'], ['co', 'u', 'n', 't', 'e', 'r', 'po', 'int'], ['to'], ['his'], ['us', 'ua', 'l'], ['e', 'conom', 'i', 'c', 's'], [','], ['business'], [','], ['and'], ['culture'], ['far', 'e'], ['.']]\n"
          ]
        }
      ],
      "source": [
        "example_sentence = next(data_loader)[1][2]\n",
        "tokenized = wptokenizer.tokenize(example_sentence)\n",
        "print(f'Example sentence: {example_sentence}')\n",
        "print(f'Tokenized:{tokenized}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_SsgrPzGlaO",
        "outputId": "f08faad5-f191-44d7-95cd-d96c7a2c5a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example sentence: Science, Politics Collide in Election Year (AP) AP - With more than 4,000 scientists, including 48 Nobel Prize winners, having signed a statement opposing the Bush administration's use of scientific advice, this election year is seeing a new development in the uneasy relationship between science and politics.\n",
            "Tokenized:[['s', 'c', 'i', 'e', 'n', 'c', 'e'], [','], ['politic', 's'], ['co', 'll', 'id', 'e'], ['in'], ['election'], ['year'], ['('], ['a', 'p'], [')'], ['a', 'p'], ['-'], ['with'], ['more'], ['than'], ['4', ',000'], ['scientists'], [','], ['including'], ['4', '8'], ['no', 'be', 'l'], ['pri', 'z', 'e'], ['winn', 'ers'], [','], ['having'], ['s', 'i', 'g', 'ned'], ['a'], ['state', 'm', 'e', 'n', 't'], ['op', 'po', 'sing'], ['the'], ['bush'], ['ad', 'm', 'in', 'ist', 'r', 'at', 'ion'], [\"'s\"], ['use'], ['of'], ['s', 'c', 'i', 'e', 'n', 't', 'if', 'i', 'c'], ['ad', 'vic', 'e'], [','], ['this'], ['election'], ['year'], ['is'], ['s', 'e', 'ein', 'g'], ['a'], ['new'], ['de', 've', 'lo', 'p', 'm', 'e', 'n', 't'], ['in'], ['the'], ['u', 'n', 'e', 'as', 'y'], ['r', 'e', 'l', 'at', 'ion', 's', 'hip'], ['between'], ['s', 'c', 'i', 'e', 'n', 'c', 'e'], ['and'], ['politic', 's'], ['.']]\n"
          ]
        }
      ],
      "source": [
        "example_sentence = next(data_loader)[1][0]\n",
        "tokenized = wptokenizer.tokenize(example_sentence)\n",
        "print(f'Example sentence: {example_sentence}')\n",
        "print(f'Tokenized:{tokenized}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-8L6XLPGlaP"
      },
      "source": [
        "### Token embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXVzC9jmGlaQ"
      },
      "source": [
        "... on Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HILAhb51GlaQ"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3D0fswLGlaR",
        "outputId": "7f24e025-3c0f-463b-8d6b-0d07209050bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example sentence: Do you like raccons?\n",
            "Tokenized:['do', 'you', 'like', 'ra', '##cco', '##ns', '?']\n"
          ]
        }
      ],
      "source": [
        "#sentences = example_sentence.split('.')\n",
        "example_sentence = 'Do you like raccons? Yes, I love them!'\n",
        "example_sentence_1, example_sentence_2 = 'Do you like raccons?', 'Yes, I love them!'\n",
        "tokenized_1 = bert_tokenizer.tokenize(example_sentence_1)\n",
        "tokenized_2 = bert_tokenizer.tokenize(example_sentence_2)\n",
        "print(f'Example sentence: {example_sentence_1}')\n",
        "print(f'Tokenized:{tokenized_1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgVK5oJ6GlaT"
      },
      "source": [
        "Now that we have our tokens, we can extract embeddings for them (as with the Transformers!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA6jdNXMGlaU",
        "outputId": "b8ecb231-d1d3-4a59-ba7f-6ebb2a7c6ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input ids: [101, 2079, 2017, 2066, 10958, 21408, 3619, 1029, 102, 2748, 1010, 1045, 2293, 2068, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "tokenizer_output = bert_tokenizer(example_sentence_1, example_sentence_2, padding = 'max_length')\n",
        "print(f'Input ids: {tokenizer_output[\"input_ids\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tydbqGu5GlaU",
        "outputId": "8d35b531-069b-412a-a45a-96f6912688f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input tokens (512): ['[CLS]', 'do', 'you', 'like', 'ra', '##cco', '##ns', '?', '[SEP]', 'yes', ',', 'i', 'love', 'them', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "tokens = bert_tokenizer.convert_ids_to_tokens(tokenizer_output[\"input_ids\"])\n",
        "print(f'Input tokens ({len(tokens)}): {tokens}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61n8xi5qGlaV",
        "outputId": "8565fcf5-727e-4033-f7d0-d2d4bde91489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([512, 768])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d_model = 768 #as in the original paper\n",
        "max_seq_len = 512\n",
        "\n",
        "embedding_layer = nn.Embedding(bert_tokenizer.vocab_size, d_model)\n",
        "input_embedding = embedding_layer(torch.IntTensor(tokenizer_output[\"input_ids\"]))\n",
        "input_embedding.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg-im37zGlaY"
      },
      "source": [
        "### Position embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXUw7nilGlaZ"
      },
      "source": [
        "Add position embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuKJnDAVGlaZ"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        i = torch.arange(0,self.d_model,2, dtype=torch.float).repeat_interleave(2)[:self.d_model]\n",
        "        denominator = torch.pow(10000, 2*i/self.d_model)\n",
        "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
        "        sin_cos_argument = position/denominator\n",
        "        PE = torch.zeros(size = sin_cos_argument.shape)\n",
        "        PE[:, 0::2] = torch.sin(sin_cos_argument[:, 0::2])\n",
        "        PE[:, 1::2] = torch.cos(sin_cos_argument[:, 1::2])\n",
        "        return PE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kUoR1u9Glaa",
        "outputId": "f28c6702-699a-4774-c4e7-fc60c2c9e869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 768])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.4902,  0.1315,  0.8269,  ...,  0.4319,  0.3296,  0.1364],\n",
              "        [ 0.6519, -0.3569, -1.5178,  ..., -0.4685,  1.4497,  1.8214],\n",
              "        [ 1.0745,  0.3352,  0.6594,  ...,  1.5334, -0.4668,  1.6931],\n",
              "        ...,\n",
              "        [-2.7681,  0.7737,  0.9482,  ...,  1.4937,  0.7936,  1.9153],\n",
              "        [-1.9567,  0.2627,  0.7124,  ...,  1.4937,  0.7936,  1.9153],\n",
              "        [-1.9482, -0.6961, -0.1470,  ...,  1.4937,  0.7936,  1.9153]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer_output = bert_tokenizer(example_sentence_1, example_sentence_2, truncation=True, padding='max_length', add_special_tokens=True)\n",
        "input_embedding = embedding_layer(torch.IntTensor(tokenizer_output[\"input_ids\"]))\n",
        "print(input_embedding.size())\n",
        "\n",
        "positional_encoding_layer = PositionalEncoding(max_sequence_length=max_seq_len, d_model=d_model)\n",
        "input_embedding = input_embedding + positional_encoding_layer()\n",
        "input_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_qOfbeOGlaa"
      },
      "source": [
        "### Sentence embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaCoAap_Glab"
      },
      "source": [
        "Add sentence embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wGOHproGlab",
        "outputId": "feb4104b-3f56-4097-aae8-9f7f9dc22ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 768])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the sentence embeddings are all zeros because the tokenizer_output['token_type_ids'] tensor contains only zeros. This happens when you provide only a single sentence to the BertTokenizer.\n",
        "#The token_type_ids are used to distinguish between the first sentence (represented by 0s) and the second sentence (represented by 1s),\n",
        "#when processing sentence pairs for tasks like Next Sentence Prediction. Since only one sentence was provided, all the token type IDs are 0\n",
        "sentence_embeddings = torch.tile(torch.IntTensor(tokenizer_output['token_type_ids']).unsqueeze(1), (1, d_model))\n",
        "print(sentence_embeddings.size())\n",
        "sentence_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiorOHifGlab",
        "outputId": "3a498b00-847f-408f-b894-7360180edfc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.4902,  0.1315,  0.8269,  ...,  0.4319,  0.3296,  0.1364],\n",
              "        [ 0.6519, -0.3569, -1.5178,  ..., -0.4685,  1.4497,  1.8214],\n",
              "        [ 1.0745,  0.3352,  0.6594,  ...,  1.5334, -0.4668,  1.6931],\n",
              "        ...,\n",
              "        [-2.7681,  0.7737,  0.9482,  ...,  1.4937,  0.7936,  1.9153],\n",
              "        [-1.9567,  0.2627,  0.7124,  ...,  1.4937,  0.7936,  1.9153],\n",
              "        [-1.9482, -0.6961, -0.1470,  ...,  1.4937,  0.7936,  1.9153]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_embedding = input_embedding + sentence_embeddings\n",
        "input_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRX2tSRHGlad"
      },
      "source": [
        "### Pre-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vfQgtXuGlad"
      },
      "source": [
        "! BERT is bidirectional: this allows each word to \"see itself\", and the model could trivially predict the target word in a multi-layered context.\n",
        "\n",
        "*SOLUTION*: mask some percentage of the input tokens at random, and then predict those masked tokens! c:\n",
        "\n",
        "This is called **Masked Language Modeling (MLM)**, and it is one of the two pre-training objectives BERT has.\n",
        "\n",
        "Usually, language models are trained to predict each word in a sentence; here, BERT must predict only the masked tokens.\n",
        "\n",
        "**Masking procedure**\n",
        "\n",
        "0. Take 15% of the tokens in the input sentence\n",
        "1. $\\rightarrow$ 80% of those tokens will be replaced with the special token $\\text{[MASK]}$\n",
        "2. $\\rightarrow$ 10% of those tokens will be replaced with a random token\n",
        "3. $\\rightarrow$ 10% of those tokens will remain unchanged\n",
        "\n",
        "**Why 80-10-10?**\n",
        "\n",
        "There may be a mismatch between the pre-training and fine-tuning tasks because the latter does not involve predicting masked words in most of the downstream tasks (e.g. sentiment analysis). The model should be good not only in predicting masked tokens, but also as pre-trained model for other tasks. The advantage of this procedure is that the Transformer encoder does not know which words it will be asked to predict or which have been replaced by random words, so it is forced to keep a distributional contextual representation of every input token.\n",
        "\n",
        "- Just using the $\\text{[MASK]}$ token resulted in the model learning very little about the context of the surrounding words. This seems to occur since the model knows it can “forget” all the information about the surrounding words and focus only on the target word.\n",
        "\n",
        "- If you use the $\\text{[MASK]}$ token 80% of the time and the right word 20% of the time, the model will know that when the [MASK] is not there, then the word is correct. The network has to predict the token, but it actually gets the answer already as input. Thus, it needs to learn nothing, since it knows the non-masked token is always correct.\n",
        "\n",
        "- If you use the $\\text{[MASK]}$ token 80% of the time and a wrong word 20% of the time, the model will know when the $\\text{[MASK]}$ doesn’t appear the selected token is a wrong one, and it will just treat it like another $\\text{[MASK]}$, i.e. you would likely encounter the same problem of before (100% $\\text{[MASK]}$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcY96NKbGlad"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def mask_sentence(sentence1, sentence2 = None, add_special_tokens = True, padding = 'max_length'):\n",
        "    if sentence2:\n",
        "        inputs = bert_tokenizer(sentence1, sentence2, return_tensors='pt', add_special_tokens=add_special_tokens, truncation=True, padding=padding)\n",
        "    else:\n",
        "        inputs = bert_tokenizer(sentence1, return_tensors='pt', add_special_tokens=add_special_tokens, truncation=True, padding=padding)\n",
        "\n",
        "    inputs['labels'] = inputs.input_ids.detach().clone() #for training\n",
        "\n",
        "    rand = torch.rand(inputs.input_ids.squeeze().shape) #Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1)\n",
        "    mask_arr = (rand < 0.15) * (inputs.input_ids.squeeze() != 101) * (inputs.input_ids.squeeze() != 102) * (inputs.input_ids.squeeze() != 0) #101 is [CLS] and 102 is [SEP] and 0 is [PAD]\n",
        "    index_to_mask = torch.flatten(mask_arr.nonzero()).tolist()\n",
        "\n",
        "    index_to_mask_shuffle = random.sample(index_to_mask, int(len(index_to_mask)-(0.1 * len(index_to_mask))))\n",
        "    to_mask = int(0.8*len(index_to_mask))\n",
        "    inputs.input_ids[0, index_to_mask_shuffle[:to_mask]] = 103 #[MASK] token\n",
        "    inputs.input_ids[0, index_to_mask_shuffle[to_mask:]] = torch.LongTensor(random.sample(list(bert_tokenizer.vocab.values()), len(index_to_mask_shuffle)-to_mask)) #random token\n",
        "    return inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUiP606XGlae",
        "outputId": "f5b0be55-14dd-4e9f-ba38-0a9de7ab80be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original sentence: Do you like raccons? Yes, I love them!\n",
            "Masked sentence: [CLS] do you like ra [MASK] ##ns ? [SEP] yes , [MASK] love them ! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "masked_sentence = mask_sentence(example_sentence_1, example_sentence_2)\n",
        "print(f'Original sentence: {example_sentence_1} {example_sentence_2}')\n",
        "print(f'Masked sentence: {\" \".join(bert_tokenizer.convert_ids_to_tokens(*masked_sentence.input_ids))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHupqM9Glae"
      },
      "source": [
        "#### Pipeline with masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIMS4oCgGlaf",
        "outputId": "8370762f-0a8a-4fab-b09a-5387fb76d1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 768])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.4902,  0.1315,  0.8269,  ...,  0.4319,  0.3296,  0.1364],\n",
              "         [ 0.6519, -0.3569, -1.5178,  ..., -0.4685,  1.4497,  1.8214],\n",
              "         [ 0.6947, -1.9195,  0.1595,  ...,  1.7897, -0.2654,  0.0901],\n",
              "         ...,\n",
              "         [-2.7681,  0.7737,  0.9482,  ...,  1.4937,  0.7936,  1.9153],\n",
              "         [-1.9567,  0.2627,  0.7124,  ...,  1.4937,  0.7936,  1.9153],\n",
              "         [-1.9482, -0.6961, -0.1470,  ...,  1.4937,  0.7936,  1.9153]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_input_masked = mask_sentence(example_sentence_1, example_sentence_2)\n",
        "token_embeddings = embedding_layer(tokenized_input_masked['input_ids'])\n",
        "position_embeddings = positional_encoding_layer()\n",
        "sentence_embeddings = torch.tile(tokenized_input_masked['token_type_ids'].permute(1,0), (1, d_model)).unsqueeze(0)\n",
        "embeddings = token_embeddings + position_embeddings + sentence_embeddings\n",
        "print(embeddings.size())\n",
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JaY5Dc3Glag"
      },
      "source": [
        "During pre-training, BERT will evaluate the loss of these masked tokens, and it will backpropagate it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkNI81UTGlah"
      },
      "source": [
        "The second pre-training objective is called **Next Sentence Prediction (NSP)**.\n",
        "\n",
        "Many important downstream tasks such as Question Answering (QA) and Natural Language Inference (NLI) are based on understanding the relationship between two sentences, which is not directly captured by language modeling.\n",
        "\n",
        "When pre-traininig for a binarized NSP task, we choose the sentences A and B for each pretraining example,ì so that 50% of the time B is the actual next sentence that follows A (labeled as IsNext), and 50% of the time it is a random sentence from the corpus (labeled as NotNext).\n",
        "\n",
        "$\\text{[CLS]}$ is used for NSP.\n",
        "\n",
        "<center><img src=\"https://github.com/Abudo-S/NLP_COURSE/blob/main/BERT/img/bert_pretrain_2.svg?raw=1\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGgbTEB3Glai"
      },
      "source": [
        "### Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOxOKAhyGlaj"
      },
      "source": [
        "Just use task-specific data and additional output layers taking as input BERT's output.\n",
        "\n",
        "**Question Answering with Stanford Question Answering Dataset (SQuAD)**\n",
        "<center><img src=\"https://github.com/Abudo-S/NLP_COURSE/blob/main/BERT/img/bert_finetune_squad.svg?raw=1\"/></center>\n",
        "\n",
        "**Entailment with MNLI**\n",
        "<center><img src=\"https://github.com/Abudo-S/NLP_COURSE/blob/main/BERT/img/bert_finetune_mnli.svg?raw=1\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOM_L0vuGlal"
      },
      "source": [
        "### Hands-on: BERT!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjQrvdSQGlam"
      },
      "source": [
        "This section is (finally) dedicated to some real-world BERT use cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfQh-XjMGlap"
      },
      "source": [
        "#### MLM (Masked Language Modeling)\n",
        "MLM is a self-supervised learning task where a model is trained to predict a word that has been \"masked\" or hidden in a sentence.\n",
        "It performs the following steps under the hood:\n",
        "\n",
        "- Tokenization: The pipeline takes your input sentence and tokenizes it, converting the text into a sequence of numerical IDs. It also handles the special [MASK] token, which is a key part of the MLM task.\n",
        "\n",
        "- Model Inference: The tokenized input is passed to a pre-trained language model (like BERT or RoBERTa). The model processes the sequence and outputs a set of logits (raw scores) for each token in the vocabulary. The highest logits correspond to the most likely next words.\n",
        "\n",
        "- Prediction: The pipeline then identifies the token with the highest logit score at the masked position. It might also return the top N most likely predictions along with their scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pvKY9OlGlap",
        "outputId": "52aee86b-b997-43b6-9295-33b161ed1738"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30522\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForMaskedLM\n",
        "\n",
        "model_mlm = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "print(bert_tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izuKeoKWGlar",
        "outputId": "3c0b2f74-3d20-4947-daa9-401f977b973f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 30522])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model_mlm(**masked_sentence).logits\n",
        "logits.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-n3k7MMGlas",
        "outputId": "7eb9caba-4732-4f54-b31f-b73a2c6e06de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5, 11])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# retrieve index of [MASK]\n",
        "mask_token_index = (masked_sentence.input_ids == bert_tokenizer.mask_token_id)[0].nonzero().squeeze()\n",
        "mask_token_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tisfpelwGlas",
        "outputId": "969aebdb-0c01-4dbe-d845-60563cb23721"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([22414,  1045])\n",
            "['##bba']\n"
          ]
        }
      ],
      "source": [
        "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
        "print(predicted_token_id)\n",
        "print(bert_tokenizer.convert_ids_to_tokens([predicted_token_id[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbVedd0hGlat",
        "outputId": "11c7136e-c424-444d-c140-c45806463423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] do you like raccons? [SEP] yes, i love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] do you like ra [MASK]ns? [SEP] yes, [MASK] love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] do you like rabbans? [SEP] yes, i love them! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "prediction = torch.where(masked_sentence.input_ids == bert_tokenizer.mask_token_id, logits[0, :].argmax(axis=-1), masked_sentence.input_ids)[0]\n",
        "print(bert_tokenizer.decode(masked_sentence.labels[0]))\n",
        "print(bert_tokenizer.decode(masked_sentence.input_ids[0]))\n",
        "print(bert_tokenizer.decode(prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-3b-zabGlat"
      },
      "source": [
        "Pipeline version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRc0bOa-Glau"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "mlm_pipeline = pipeline('fill-mask', model=model_mlm, tokenizer=bert_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9U6fURZGlau",
        "outputId": "2987cb6c-39bb-42b1-bc12-47726e22394f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[CLS] do you like raccons? [SEP] yes, i [MASK] [MASK]! [SEP]'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_mask_sentence = mask_sentence(example_sentence_1, example_sentence_2, add_special_tokens = True, padding = False)\n",
        "pipeline_mask_sentence = bert_tokenizer.decode(pipeline_mask_sentence.input_ids[0])\n",
        "pipeline_mask_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCHh52QmGlaw",
        "outputId": "022e07d4-7211-44e4-e53d-2ded11d1c0d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[{'score': 0.7961465716362,\n",
              "   'token': 2079,\n",
              "   'token_str': 'do',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i do [MASK]! [SEP] [SEP]'},\n",
              "  {'score': 0.07182539254426956,\n",
              "   'token': 2572,\n",
              "   'token_str': 'am',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i am [MASK]! [SEP] [SEP]'},\n",
              "  {'score': 0.017079079523682594,\n",
              "   'token': 2031,\n",
              "   'token_str': 'have',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i have [MASK]! [SEP] [SEP]'},\n",
              "  {'score': 0.015040510334074497,\n",
              "   'token': 2113,\n",
              "   'token_str': 'know',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i know [MASK]! [SEP] [SEP]'},\n",
              "  {'score': 0.013145454227924347,\n",
              "   'token': 2066,\n",
              "   'token_str': 'like',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i like [MASK]! [SEP] [SEP]'}],\n",
              " [{'score': 0.5938681960105896,\n",
              "   'token': 2079,\n",
              "   'token_str': 'do',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i [MASK] do! [SEP] [SEP]'},\n",
              "  {'score': 0.10474661737680435,\n",
              "   'token': 2205,\n",
              "   'token_str': 'too',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i [MASK] too! [SEP] [SEP]'},\n",
              "  {'score': 0.04078187793493271,\n",
              "   'token': 2009,\n",
              "   'token_str': 'it',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i [MASK] it! [SEP] [SEP]'},\n",
              "  {'score': 0.037437815219163895,\n",
              "   'token': 2025,\n",
              "   'token_str': 'not',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i [MASK] not! [SEP] [SEP]'},\n",
              "  {'score': 0.026387104764580727,\n",
              "   'token': 2068,\n",
              "   'token_str': 'them',\n",
              "   'sequence': '[CLS] [CLS] do you like raccons? [SEP] yes, i [MASK] them! [SEP] [SEP]'}]]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlm_pipeline(pipeline_mask_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aehdfN55Glaw"
      },
      "source": [
        "#### NSP (Next Sentence Prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl2eeXu1Glax"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForNextSentencePrediction\n",
        "\n",
        "model_nsp = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzFA6-H9Glax"
      },
      "source": [
        "labels (torch.LongTensor of shape (batch_size,), optional) — Labels for computing the next sequence prediction (classification) loss. Input should be a sequence pair (see input_ids docstring). Indices should be in [0, 1]:\n",
        "- 0 indicates sequence B is a continuation of sequence A,\n",
        "- 1 indicates sequence B is a random sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM1oHC5BGlax",
        "outputId": "3c4a4118-6d72-41ad-e7e0-8b92b0d29f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 5.0871, -4.1504]], grad_fn=<AddmmBackward0>)\n",
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "masked_sentence['labels'] = torch.LongTensor([0])\n",
        "outputs = model_nsp(**masked_sentence)\n",
        "logits = outputs.logits\n",
        "print(logits)\n",
        "print(torch.argmax(logits)) #isNext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMIXKHLiGlay",
        "outputId": "2959b9aa-ac81-458c-b0b6-476e695fdc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-3.0729,  5.9056]], grad_fn=<AddmmBackward0>)\n",
            "tensor(1)\n"
          ]
        }
      ],
      "source": [
        "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
        "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
        "#next_sentence = \"This is what happens in Italian restaurants.\"\n",
        "encoding = bert_tokenizer(prompt, next_sentence, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model_nsp(**encoding, labels=torch.LongTensor([1]))\n",
        "logits = outputs.logits\n",
        "print(logits)\n",
        "print(torch.argmax(logits))# next sentence was random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE4wCR1hGlay"
      },
      "source": [
        "#### Sequence Classification with MNLI (Multi-Genre Natural Language Inference)\n",
        "Multi-Genre Natural Language Inference, is a large-scale dataset used for evaluating and training models on the task of Natural Language Inference (NLI).\n",
        "\n",
        "NLI is the task of determining the relationship between a pair of sentences. Given a premise (a statement) and a hypothesis (a second statement), a model must classify their relationship into one of three categories:\n",
        "- Entailment: The hypothesis is logically derived from the premise. (e.g., Premise: \"A dog is running.\" Hypothesis: \"An animal is moving.\")\n",
        "\n",
        "- Contradiction: The hypothesis directly contradicts the premise. (e.g., Premise: \"The cat is sleeping on the mat.\" Hypothesis: \"The cat is awake.\")\n",
        "\n",
        "- Neutral: The relationship is neither entailment nor contradiction. (e.g., Premise: \"The man is at the park.\" Hypothesis: \"The woman is at the store.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzNEGuoUGlaz"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "mnli_dataset = load_dataset('multi_nli', split='train[:100]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4NnDOlHGla0",
        "outputId": "ea6a9db1-67f9-4b82-e7d9-855231d758bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'promptID': 60529,\n",
              " 'pairID': '60529c',\n",
              " 'premise': \"At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\",\n",
              " 'premise_binary_parse': \"( ( At ( ( the end ) ( of Rue ) ) ) ( ( des Francs-Bourgeois ) ( ( is ( what ( many ( consider ( to ( ( be ( ( ( ( ( the ( city 's ) ) ( ( most handsome ) ( residential square ) ) ) , ) ( the ( Place ( des Vosges ) ) ) ) , ) ) ( with ( its ( stone ( and ( red ( brick facades ) ) ) ) ) ) ) ) ) ) ) ) . ) ) )\",\n",
              " 'premise_parse': \"(ROOT (S (PP (IN At) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NNP Rue))))) (NP (NNP des) (NNP Francs-Bourgeois)) (VP (VBZ is) (SBAR (WHNP (WP what)) (S (NP (DT many)) (VP (VBP consider) (S (VP (TO to) (VP (VB be) (NP (NP (NP (DT the) (NN city) (POS 's)) (ADJP (RBS most) (JJ handsome)) (JJ residential) (NN square)) (, ,) (NP (DT the) (NNP Place) (NNP des) (NNPS Vosges)) (, ,)) (PP (IN with) (NP (PRP$ its) (NN stone) (CC and) (JJ red) (NN brick) (NNS facades)))))))))) (. .)))\",\n",
              " 'hypothesis': 'Place des Vosges is constructed entirely of gray marble.',\n",
              " 'hypothesis_binary_parse': '( ( Place ( des Vosges ) ) ( ( is ( ( constructed entirely ) ( of ( gray marble ) ) ) ) . ) )',\n",
              " 'hypothesis_parse': '(ROOT (S (NP (NNP Place) (FW des) (NNP Vosges)) (VP (VBZ is) (VP (VBN constructed) (ADVP (RB entirely)) (PP (IN of) (NP (JJ gray) (NN marble))))) (. .)))',\n",
              " 'genre': 'travel',\n",
              " 'label': 2}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_mnli = mnli_dataset[9] #entailment (0), neutral (1), contradiction (2)\n",
        "example_mnli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "511LSPgkGla0",
        "outputId": "a97d5854-377e-4a05-ef5d-a1c60281195c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\n",
            "Place des Vosges is constructed entirely of stone and bricks.\n"
          ]
        }
      ],
      "source": [
        "print(example_mnli['premise'])\n",
        "example_mnli['hypothesis'] = \"Place des Vosges is constructed entirely of stone and bricks.\"\n",
        "print(example_mnli['hypothesis'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3myVwGdGla1"
      },
      "outputs": [],
      "source": [
        "def mnli_preprocess_function(examples):\n",
        "    return bert_tokenizer(examples['premise'], examples['hypothesis'], truncation=True, padding = True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJF9owyZGla1",
        "outputId": "bbd44680-363e-4485-f977-f56428dd51e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Premise: At the end of Rue des Francs-Bourgeois is what many consider to be the city's most handsome residential square, the Place des Vosges, with its stone and red brick facades.\n",
            "Hypothesis: Place des Vosges is constructed entirely of stone and bricks.\n",
            "After preprocessing: [CLS] at the end of rue des francs - bourgeois is what many consider to be the city's most handsome residential square, the place des vosges, with its stone and red brick facades. [SEP] place des vosges is constructed entirely of stone and bricks. [SEP]\n"
          ]
        }
      ],
      "source": [
        "print(f'Premise: {example_mnli[\"premise\"]}')\n",
        "print(f'Hypothesis: {example_mnli[\"hypothesis\"]}')\n",
        "example_mnli_processed = mnli_preprocess_function(example_mnli)\n",
        "print(f'After preprocessing: {bert_tokenizer.decode(example_mnli_processed[\"input_ids\"][0])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQbEN-p7Gla2"
      },
      "outputs": [],
      "source": [
        "encoded_mnli_dataset = mnli_dataset.map(mnli_preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OOYo8F3Gla3",
        "outputId": "bb3cf2ac-817a-41cc-a324-a4127ef99e78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/flint/.pyenv/versions/3.9.17/envs/nlp/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_mnli = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-MNLI\") #entailment (1), neutral (2), contradiction (0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZfixpisGla4",
        "outputId": "2e7129f7-2505-4085-e9a8-9b2efa49b156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-2.2080,  0.2117,  1.4080]], grad_fn=<AddmmBackward0>)\n",
            "tensor(2)\n"
          ]
        }
      ],
      "source": [
        "outputs = model_mnli(**example_mnli_processed)\n",
        "logits = outputs.logits\n",
        "print(logits)\n",
        "print(torch.argmax(logits))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGZ9NktBGla5"
      },
      "source": [
        "#### Question Answering with SQuAD (Stanford Question Answering Dataset)\n",
        "It is a widely used benchmark dataset for the task of extractive question answering in NLP. It's used to train and evaluate models that are designed to read a passage of text and find the correct answer to a question within that passage. The answer is always a span of text taken directly from the given passage.\n",
        "A model must not only be able to find the answer when it exists, but also to recognize when no answer is present and abstain from answering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4MqDH2kGla5"
      },
      "outputs": [],
      "source": [
        "squad_dataset = load_dataset(\"squad\", split = 'train[:100]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNb4QA1PGla6",
        "outputId": "513bb42f-64e0-4efb-a93a-a41813bb8654"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '5733be284776f41900661182',\n",
              " 'title': 'University_of_Notre_Dame',\n",
              " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "squad_example = squad_dataset[0]\n",
        "squad_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPQjjZXgGla7",
        "outputId": "840f8d93-ae75-425f-8c76-8cac480defac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at csarron/bert-base-uncased-squad-v1 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\n",
        "  \"question-answering\",\n",
        "  model=\"csarron/bert-base-uncased-squad-v1\",\n",
        "  tokenizer=\"csarron/bert-base-uncased-squad-v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-S2R2dBmGla8",
        "outputId": "545e7153-5f77-43d6-8f5a-6da49d3f7e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'score': 0.9795625805854797, 'start': 515, 'end': 541, 'answer': 'Saint Bernadette Soubirous'}\n"
          ]
        }
      ],
      "source": [
        "predictions = qa_pipeline({\n",
        "  'context': squad_example['context'],\n",
        "  'question': squad_example['question']\n",
        "})\n",
        "\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8FvrkPHGla9"
      },
      "source": [
        "## Bert Variants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_UK28KGla-"
      },
      "source": [
        "<center><img src=\"https://github.com/Abudo-S/NLP_COURSE/blob/main/BERT/img/bert_models.png?raw=1\" width = \"70%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZr0uBKOGla_"
      },
      "source": [
        "## Bert Extensions\n",
        "-[Performance-focused] RoBERTa (Robustly Optimized BERT Pre-training Approach): This model showed that BERT's performance could be significantly improved by simply training it longer on a much larger dataset, with larger batch sizes, and by removing the Next Sentence Prediction (NSP) task. It also introduced dynamic masking, where the masked tokens are changed during different epochs to make the model more robust.\n",
        "-[Efficiency-focused] DistilBERT: This is a distilled version of BERT. It was trained using knowledge distillation, a technique where a smaller model (the student) learns to mimic the behavior of a larger, pre-trained model (the teacher). DistilBERT has about 40% fewer parameters than BERT-base, making it faster and more memory-efficient while retaining most of its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9F69WiEGla_"
      },
      "source": [
        "<center><img src=\"https://github.com/Abudo-S/NLP_COURSE/blob/main/BERT/img/bert_variants.png?raw=1\" width = \"70%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZRa9Qh-GlbC"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FznqkcK4GlbD"
      },
      "source": [
        "Papers:\n",
        "- Radford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. “Improving Language Understanding by Generative Pre-Training,” 2019, 12.\n",
        "- Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. “BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics, 2019. https://doi.org/10.18653/v1/N19-1423.\n",
        "- Wu, Yonghui, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, et al. “Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation.” ArXiv:1609.08144 [Cs], October 8, 2016. http://arxiv.org/abs/1609.08144.\n",
        "- Sennrich, Rico, Barry Haddow, and Alexandra Birch. “Neural Machine Translation of Rare Words with Subword Units.” arXiv, June 10, 2016. https://doi.org/10.48550/arXiv.1508.07909.\n",
        "- Schuster, Mike, and Kaisuke Nakajima. “Japanese and Korean Voice Search.” In 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5149–52, 2012. https://doi.org/10.1109/ICASSP.2012.6289079.\n",
        "- Liu, Yinhan, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. “RoBERTa: A Robustly Optimized BERT Pretraining Approach.” ArXiv:1907.11692 [Cs], July 26, 2019. http://arxiv.org/abs/1907.11692.\n",
        "- Sanh, Victor, Lysandre Debut, Julien Chaumond, and Thomas Wolf. “DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter.” arXiv, February 29, 2020. https://doi.org/10.48550/arXiv.1910.01108.\n",
        "\n",
        "Online resources / tutorials:\n",
        "- https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/bert#bert\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tawSxdMtGlbF"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}